{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cDp9FXb9L9dw"
   },
   "source": [
    "Baseado em: https://github.com/rcmalli/keras-squeezenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qOIy4MreL9dy"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9HcTL0pNL9d3"
   },
   "source": [
    "### Imports e funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9wjGsJUNL9d5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from random import sample, seed\n",
    "seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (15,15) # Make the figures a bit bigger\n",
    "\n",
    "# Keras imports\n",
    "from keras.layers import Input, Convolution2D, MaxPooling2D, Activation, concatenate, Dropout, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.utils import get_file\n",
    "\n",
    "#read all images (jpg, png) in imgDirPath and resize to 227x227\n",
    "def readImagesFromDir(imgDirPath):\n",
    "    fileNames = os.listdir(imgDirPath)\n",
    "    imagePaths = [os.path.join(imgDirPath,img) for img in fileNames if img[-3:] in ['jpg', 'png']]\n",
    "    imageList = [load_img(img, target_size=(227, 227)) for img in imagePaths]\n",
    "    imageList = [img_to_array(img) for img in imageList]\n",
    "    return imageList, fileNames\n",
    "\n",
    "#plot the imgList\n",
    "def plotImages(imgList):\n",
    "    for i in range(len(imgList)):\n",
    "        plotImage(imgList[i])\n",
    "        \n",
    "        \n",
    "def plotImage(img):\n",
    "    fig = plt.figure(figsize=(5,5))\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    ax.imshow(np.uint8(img), interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xWqtOCRzL9d-"
   },
   "source": [
    "# Módulo Fire\n",
    "<img src=\"./books_images/fire.png\" width=30% height=30%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gldFHKW9L9d_"
   },
   "outputs": [],
   "source": [
    "sq1x1 = \"squeeze1x1\"\n",
    "exp1x1 = \"expand1x1\"\n",
    "exp3x3 = \"expand3x3\"\n",
    "relu = \"relu_\"\n",
    "\n",
    "# Modular function for Fire Node\n",
    "def fire_module(x, fire_id, squeeze=16, expand=64):\n",
    "    s_id = 'fire' + str(fire_id) + '/'\n",
    "\n",
    "    channel_axis = 3\n",
    "    \n",
    "    x = Convolution2D(squeeze, (1, 1), padding='valid', name=s_id + sq1x1)(x)\n",
    "    x = Activation('relu', name=s_id + relu + sq1x1)(x)\n",
    "\n",
    "    left = Convolution2D(expand, (1, 1), padding='valid', name=s_id + exp1x1)(x)\n",
    "    left = Activation('relu', name=s_id + relu + exp1x1)(left)\n",
    "\n",
    "    right = Convolution2D(expand, (3, 3), padding='same', name=s_id + exp3x3)(x)\n",
    "    right = Activation('relu', name=s_id + relu + exp3x3)(right)\n",
    "\n",
    "    x = concatenate([left, right], axis=channel_axis, name=s_id + 'concat')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eeDL5mQjL9eB"
   },
   "source": [
    "# SqueezeNet\n",
    "<img src=\"./books_images/squeezenet.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2RbeugX_L9eC"
   },
   "outputs": [],
   "source": [
    "def SqueezeNet(input_shape=None, weights_path=None, classes=1000):\n",
    "    \"\"\"Instantiates the SqueezeNet architecture.\n",
    "    \"\"\"\n",
    "    img_input = Input(shape=input_shape)\n",
    "\n",
    "    x = Convolution2D(64, (3, 3), strides=(2, 2), padding='valid', name='conv1')(img_input)\n",
    "    x = Activation('relu', name='relu_conv1')(x)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool1')(x)\n",
    "\n",
    "    x = fire_module(x, fire_id=2, squeeze=16, expand=64)\n",
    "    x = fire_module(x, fire_id=3, squeeze=16, expand=64)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool3')(x)\n",
    "\n",
    "    x = fire_module(x, fire_id=4, squeeze=32, expand=128)\n",
    "    x = fire_module(x, fire_id=5, squeeze=32, expand=128)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool5')(x)\n",
    "\n",
    "    x = fire_module(x, fire_id=6, squeeze=48, expand=192)\n",
    "    x = fire_module(x, fire_id=7, squeeze=48, expand=192)\n",
    "    x = fire_module(x, fire_id=8, squeeze=64, expand=256)\n",
    "    x = fire_module(x, fire_id=9, squeeze=64, expand=256)\n",
    "    \n",
    "    x = Dropout(0.5, name='drop9')(x)\n",
    "\n",
    "    x = Convolution2D(classes, (1, 1), padding='valid', name='conv10')(x)\n",
    "    x = Activation('relu', name='relu_conv10')(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Activation('softmax', name='loss')(x)\n",
    "\n",
    "    model = Model(img_input, x, name='squeezenet')\n",
    "    \n",
    "    if weights_path != None:\n",
    "        model.load_weights(weights_path)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6e9vjoEmL9eG"
   },
   "source": [
    "Após definir a arquitetura, podemos criar nosso modelo passando o tamanho das imagens de entrada e um possível arquivo com os pesos treinados para o modelo. No nosso caso, usaremos os pesos para o modelo treinado usando a biblioteca [ImageNet](http://www.image-net.org/). O arquivo está disponível no link abaixo:\n",
    "\n",
    "https://github.com/rcmalli/keras-squeezenet/releases/download/v1.0/squeezenet_weights_tf_dim_ordering_tf_kernels.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d5pAPTtVL9eH"
   },
   "outputs": [],
   "source": [
    "squeezeNetModel = SqueezeNet((227,227,3), \"squeezenet_weights_tf_dim_ordering_tf_kernels.h5\")\n",
    "print(squeezeNetModel.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gw98PGhML9eP"
   },
   "source": [
    "### Explicações e Avaliação\n",
    "\n",
    "ImageNet é esforço de pesquisa ainda em evolução para criar um dataset de imagens acessível para pesquisadores poderem testar suas pesquisas. Atualmente ela mais de 14 milhões de imagens divididas em 21841 classes. A arquitetura utilizada aqui foi treinada sobre a [ImageNet Kraggle Competition](https://www.kaggle.com/c/imagenet-object-localization-challenge), que continha um subset da ImageNet com 150.000 figuras e 1000 classes distintas.\n",
    "\n",
    "No exemplo desse notebook, baixamos algumas imagens da ImageNet original e vamos avaliar como nosso modelo pré-treinado se sai para esse subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XgFv6ZXwL9eQ"
   },
   "outputs": [],
   "source": [
    "imgList, fileNames = readImagesFromDir('images')\n",
    "plotImages(imgList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M2u-9WzaL9eT"
   },
   "source": [
    "### Predizendo as imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9RQ6mWP2L9eU"
   },
   "outputs": [],
   "source": [
    "# prepare the image for ResNet50\n",
    "processed_images = np.array([preprocess_input(img.copy()) for img in imgList])\n",
    "\n",
    "# get the predicted probabilities for each class\n",
    "predictions = squeezeNetModel.predict(processed_images, verbose=0)\n",
    "\n",
    "print(\"Shape of predictions --> \", predictions.shape)\n",
    "print(\"Prediction of the first image:\\n\", predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ylz-MdmIL9eZ"
   },
   "source": [
    "### Avaliando os resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wiTMvBRSL9ec"
   },
   "outputs": [],
   "source": [
    "# Convert the probabilities to class labels\n",
    "# We will get top 5 predictions which is the default\n",
    "imagePredictions = decode_predictions(predictions)\n",
    "i = 0\n",
    "for pred in imagePredictions:\n",
    "    plotImage(imgList[i])\n",
    "    for possibleClass in pred:\n",
    "        print(possibleClass[1], possibleClass[2])\n",
    "    print(\"\\n\")\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Bootcamp - SqueezeNet.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
